"""
Analyze RSA master dataset for subject-level statistics.

Reads rsa_results_master.csv, selects the subject-level rows generated by
compile_rsa_results.py, and computes summary statistics plus Holm-adjusted
one-sample t-tests against a specified baseline accuracy.
"""
from __future__ import annotations

import argparse
import math
from pathlib import Path
from typing import Tuple, Optional

import numpy as np
import pandas as pd
from scipy import stats as scipy_stats  # type: ignore


MASTER_FILENAME = "rsa_results_master.csv"


def load_master_csv(csv_path: Path) -> pd.DataFrame:
    df = pd.read_csv(csv_path)
    required = {"ClassA", "ClassB", "Seed", "Subject", "Accuracy"}
    missing = required - set(df.columns)
    if missing:
        raise KeyError(f"Missing required columns {missing} in {csv_path}")
    return df


def filter_subject_rows(df: pd.DataFrame) -> pd.DataFrame:
    if "RecordType" not in df.columns:
        raise ValueError(
            "Master CSV lacks the 'RecordType' column. "
            "Please re-run scripts/compile_rsa_results.py to regenerate subject-level rows."
        )
    mask = df["RecordType"].astype(str).str.lower() == "subject"
    if not mask.any():
        raise ValueError(
            "No subject-level rows found (RecordType=='subject'). "
            "Ensure predictions CSVs exist and re-run compile_rsa_results.py."
        )
    return df[mask].copy()


def _t_test(values: np.ndarray, baseline: float) -> Tuple[float, float]:
    values = values[~np.isnan(values)]
    if values.size < 2:
        return float("nan"), float("nan")
    t_stat, p_value = scipy_stats.ttest_1samp(values, baseline, nan_policy="omit")
    return float(t_stat), float(p_value)


def _apply_holm_correction(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        df = df.copy()
        df["p_value_holm"] = []
        return df
    pvals = df["p_value"].to_numpy()
    order = np.argsort(pvals, kind="mergesort")
    m = len(pvals)
    adjusted = np.full(m, np.nan, dtype=float)
    running_max = 0.0
    for idx_in_order, row_idx in enumerate(order):
        p = pvals[row_idx]
        if np.isnan(p):
            adjusted[row_idx] = np.nan
            continue
        factor = m - idx_in_order
        holm = min(1.0, p * factor)
        running_max = max(running_max, holm)
        adjusted[row_idx] = running_max
    df = df.copy()
    df["p_value_holm"] = adjusted
    return df


def _pair_chance_rate(group: pd.DataFrame, requested: Optional[float]) -> float:
    """
    Return the requested baseline for statistical testing.

    Uses theoretical baseline (default 50%) for clean hypothesis testing.
    Empirical ChanceRate is logged for QC but not used, since slight
    imbalances due to trial rejection should not affect cognitive testing.

    Args:
        group: DataFrame with subject rows for one pair
        requested: Theoretical baseline (default 50%)

    Returns:
        Baseline chance rate for t-test
    """
    baseline = requested if requested is not None else 50.0

    # Check empirical chance for QC (warn if major deviation)
    chance_col = group.get("ChanceRate")
    if chance_col is not None and not chance_col.dropna().empty:
        empirical = float(chance_col.dropna().iloc[0])
        if not math.isclose(empirical, baseline, abs_tol=2.0):
            print(
                f"[analyze_rsa_stats] Note: empirical chance {empirical:.2f}% "
                f"differs from theoretical baseline {baseline:.2f}% "
                f"(likely due to trial rejection). Using theoretical baseline for testing."
            )

    return baseline


def compute_subject_ttests(
    df: pd.DataFrame,
    baseline: Optional[float] = 50.0,
    expected_n_subjects: Optional[int] = None,
) -> pd.DataFrame:
    """
    Compute subject-level t-tests for each pair.

    Args:
        df: Subject-level rows from rsa_results_master.csv
        baseline: Theoretical baseline (default 50%)
        expected_n_subjects: Expected number of subjects for QC warnings (optional)

    Returns:
        DataFrame with summary statistics and Holm-corrected p-values
    """
    results = []
    for (class_a, class_b), group in df.groupby(["ClassA", "ClassB"]):
        subject_means = (
            group.groupby("Subject")["Accuracy"]
            .mean()
            .dropna()
        )
        acc_values = subject_means.astype(float).to_numpy()
        n_subjects = int(np.count_nonzero(~np.isnan(acc_values)))

        # QC check for expected subject count
        if expected_n_subjects is not None and n_subjects < expected_n_subjects:
            print(
                f"[analyze_rsa_stats] Warning: {class_a}v{class_b} has only {n_subjects} subjects "
                f"(expected {expected_n_subjects}). Some predictions may be missing."
            )

        chance = _pair_chance_rate(group, baseline)
        t_stat, p_value = _t_test(acc_values, chance)
        results.append(
            {
                "ClassA": int(class_a),
                "ClassB": int(class_b),
                "n_subjects": n_subjects,
                "mean_accuracy": float(np.nanmean(acc_values))
                if acc_values.size
                else float("nan"),
                "std_accuracy": float(np.nanstd(acc_values, ddof=1))
                if acc_values.size > 1
                else float("nan"),
                "t_stat": t_stat,
                "p_value": p_value,
                "chance_rate": chance,
            }
        )
    summary_df = pd.DataFrame(results)
    return _apply_holm_correction(summary_df)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Analyze RSA master dataset statistics.")
    parser.add_argument(
        "--csv",
        type=Path,
        default=Path("results") / "runs" / MASTER_FILENAME,
        help="Path to rsa_results_master.csv.",
    )
    parser.add_argument(
        "--baseline",
        type=float,
        default=50.0,
        help="Theoretical baseline accuracy for significance testing (default: 50%%).",
    )
    parser.add_argument(
        "--expected-subjects",
        type=int,
        default=None,
        help="Expected number of subjects for QC warnings (optional).",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=None,
        help="Optional path to write the summary CSV. Defaults to printing only.",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    df = load_master_csv(args.csv)
    subject_df = filter_subject_rows(df)
    summary_df = compute_subject_ttests(
        subject_df,
        baseline=args.baseline,
        expected_n_subjects=args.expected_subjects,
    )

    if args.output:
        args.output.parent.mkdir(parents=True, exist_ok=True)
        summary_df.to_csv(args.output, index=False)
        print(f"[analyze_rsa_stats] Summary written to {args.output.resolve()}")
    else:
        print(summary_df.to_string(index=False))


if __name__ == "__main__":
    main()
