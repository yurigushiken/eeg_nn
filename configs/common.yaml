# Training
seed: 1
epochs: 120
early_stop: 20
inner_val_frac: 0.2
save_ckpt: false
batch_size: 16
lr: 0.0003

# Optuna optimization objective
# optuna_objective: inner_mean_macro_f1  # inner_mean_macro_f1 | inner_mean_min_per_class_f1 | inner_mean_acc

# Data controls (work with materialized)
crop_ms: null                    # e.g., [0, 600]
exclude_channel_list: non_scalp  # default: exclude non‑scalp channels for all searches
include_channels: null           # explicit keep-only (alternative to exclude)
channel_lists:
  non_scalp: [E1, E8, E14, E17, E21, E25, E32, E38, E43, E44, E48, E49, E56, E63, E68, E73, E81, E88, E94, E99, E107, E113, E114, E119, E120, E121, E125, E126, E127, E128]
  parietal_occipital: [E54, E55, E59, E60, E61, E62, E66, E67, E71, E72, E76, E77, E78, E79, E84, E85, E91]  # 17 channels: Central parietal + bilateral occipital (verified by 3D position analysis)
  posterior_hemisphere: [E47, E50, E51, E52, E53, E54, E55, E58, E59, E60, E61, E62, E65, E66, E67, E70, E71, E72, E75, E76, E77, E78, E79, E83, E84, E85, E86, E90, E91, E92, E96, E97, E98, E101]  # 34 channels: Whole posterior (parietal + occipital + posterior temporal)
cz_step: 0                

# Dataset caching (in-process)
dataset_cache_memory: true

# Post-hoc statistics defaults
stats:
  alpha: 0.05              # significance level for per-subject tests
  chance_rate: null        # if null, defaults to 1/num_classes
  multitest: fdr           # none | fdr
  per_subject_metric: acc  # currently accuracy used for binomial
  ci_method: t             # t | bootstrap
  bootstrap_iters: 2000    # used if ci_method=bootstrap
  glmm: false              # attempt GLMM (or robust logit fallback) in post-hoc
  glmm_random_effects: [subject]  # random intercepts by subject
  run_posthoc_after_train: true  # auto-run posthoc after train.py

# Permutation testing defaults
permutation:
  enable: false
  n_permutations: 200
  scope: within_subject   # within_subject | global
  stratified: true
  seed: 123
  block_key: null         # optional: shuffle within (subject, block_key)

# Decision layer (ordinal adjacent-pair refinement, optional post-hoc)
# Purpose: Reduce systematic adjacent-class confusions (e.g., 2↔3) in ordinal tasks
# Method: Tunes threshold θ per outer fold on inner validation data, applies frozen to outer test
decision_layer:
  enable: false                     # Set true to enable (default: disabled for compatibility)
  metric: optuna_objective          # Metric to optimize during θ tuning (or specify: macro_f1, min_per_class_f1, etc.)
  theta_grid: [0.30, 0.70, 0.01]    # [start, stop, step] for θ sweep (default: 0.30→0.70 in 0.01 increments)
  min_activation_trials: 50         # Minimum adjacent-pair trials required; else fallback θ=0.50
  save_activation_stats: true       # Persist per-fold activation rates and metric deltas

# Output artifact toggles
outputs:
  write_outer_eval_csv: true
  write_test_predictions_csv: true
  write_learning_curves_csv: true
  write_splits_indices_json: true