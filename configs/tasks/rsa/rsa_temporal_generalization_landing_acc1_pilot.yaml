# Temporal Generalization (PILOT) â€” Landing/Target digit (change trials), ACC==1
#
# Goal:
# - Train on ONE landing-digit pair and ONE train window
# - Evaluate across ALL test windows (temporal generalization column)
# - Verify artifacts: *_generalization.csv per run dir
#
# Scientific explicitness:
# - rsa_conditions is explicitly set (no inference from task)
# - task is selected at runtime: use --task rsa_landing_binary

model_name: eegnex
optuna_objective: inner_mean_min_per_class_f1

# Pilot seed
seeds: [49]

# Explicit landing digit codes (y labels come from landing digit)
# For pilot, just one pair: (1,2)
rsa_conditions: [1, 2]

temporal:
  epoch_ms: 500
  window_ms: 50
  stride_ms: 20
  # Pilot: only train on a single window (still tests across all windows)
  train_windows: [[180, 230]]

temporal_generalization:
  enabled: true
  write_predictions: true

# Data
materialized_dir: data_preprocessed/hpf_1.5_lpf_35_baseline-on-avgref
crop_ms: null
exclude_channel_list: non_scalp
trial_filter: acc1

# Training schedule (pilot: keep it short)
epochs: 8
early_stop: 3
batch_size: 128
lr: 0.001
inner_n_folds: 5
n_folds: 6
outer_eval_mode: ensemble

# Regularization
weight_decay: 0.000025
drop_prob: 0.5
scheduler_patience: 3
lr_warmup_frac: 0.0
lr_warmup_init: 0.0

# EEGNeX architecture (50ms windows safe pooling)
filter_1: 8
filter_2: 32
kernel_block_1_2: 32
kernel_block_4: 16
kernel_block_5: 16
avg_pool_block4: 4
avg_pool_block5: 4
dilation_block_4: 2
dilation_block_5: 4
depth_multiplier: 2
activation: elu
max_norm_conv: 1.0
max_norm_linear: 0.25

dataset_cache_memory: true

# Output (kept for audit; CLI --output-dir should match)
output_dir: results/runs/rsa_temporal_generalization_landing_acc1_pilot
results_filename: rsa_temporal_results.csv


